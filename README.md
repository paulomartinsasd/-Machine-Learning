# Projeto de Machine Learning: PrevisÃ£o de Valor de Venda

Este projeto utiliza um conjunto de dados pÃºblicos da Olist (e-commerce brasileiro) para construir um pipeline completo de Machine Learning, para prever o valor total de uma venda. O projeto abrange desde a combinaÃ§Ã£o e limpeza dos dados atÃ© o treinamento de um modelo preditivo e sua disponibilizaÃ§Ã£o em um dashboard interativo.

## ğŸ“ Estrutura de Pastas

Para que os scripts funcionem corretamente, seu projeto deve seguir a seguinte estrutura de pastas e arquivos:

```
seu-projeto/
â”‚
â”‚â”€â”€ data/
â”‚   â””â”€â”€ (Esta pasta serÃ¡ criada pelo script 'main.py')
â”‚
â”œâ”€â”€ data_processed/
â”‚   â””â”€â”€ (Esta pasta serÃ¡ criada pelo script 'preparar_dados.py')
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_geolocation_dataset.csv
â”‚   â”œâ”€â”€ ... (todos os 9 arquivos .csv da Olist)
â”‚   â””â”€â”€ product_category_name_translation.csv
â”‚
â”œâ”€â”€ img/
â”‚   â””â”€â”€ (Esta pasta serÃ¡ criada pelo script 'main.py')
â”‚
â”œâ”€â”€ outros/
â”‚   â””â”€â”€ (Esta pasta serÃ¡ criada pelo script 'dashboard.py')
â”‚
â”œâ”€â”€ preparar_dados.py
â”œâ”€â”€ engenharia_features.py
â”œâ”€â”€ main.py
â””â”€â”€ dashboard.py
```

## DataBase

Primeiro vocÃª precisa criar uma pasta com o nome de database e depois baixar e salvar nessa pasta os arquivos csv do [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) que ao todo sÃ£o 9 arquivos.


## ğŸ› ï¸ PrÃ©-requisitos e InstalaÃ§Ã£o

Antes de rodar os scripts, Ã© necessÃ¡rio instalar todas as bibliotecas Python utilizadas.

1.  Crie um arquivo chamado `requirements.txt` na pasta principal do seu projeto.
2.  Copie e cole o seguinte conteÃºdo dentro do arquivo `requirements.txt`:
    ```
    pandas
    numpy
    scikit-learn
    joblib
    streamlit
    fpdf
    matplotlib
    seaborn
    ```
3.  Abra o terminal na pasta do seu projeto e execute o seguinte comando para instalar todas as dependÃªncias de uma sÃ³ vez:
    ```bash
    pip install -r requirements.txt
    ```

## ğŸš€ Como Rodar o Projeto (Ordem de ExecuÃ§Ã£o)

Ã‰ **essencial** executar os scripts na ordem correta, pois cada um depende dos arquivos gerados pelo anterior.

### Passo 1: Preparar e Combinar os Dados
Este script pega os 9 arquivos `.csv` da pasta `data/`, combina todos eles em um Ãºnico dataset e o salva.

```bash
python preparar_dados.py
```
* **Entrada:** Os 9 arquivos `.csv` na pasta `data/`.
* **SaÃ­da:** Cria a pasta `data_processed/` e, dentro dela, o arquivo `olist_dataset_completo.csv`.

### Passo 2: Limpeza e Engenharia de Features
Este script carrega o dataset combinado, realiza a limpeza, remove colunas desnecessÃ¡rias e cria novas features preditivas (como tempo de entrega, dia da semana, etc.).

```bash
python engenharia_features.py
```
* **Entrada:** `data_processed/olist_dataset_completo.csv`.
* **SaÃ­da:** O arquivo `dataset_para_modelo.csv` na pasta `database/`, pronto para o treinamento.

### Passo 3: Treinar o Modelo de Machine Learning
Este script carrega o dataset final processado, treina o modelo `RandomForestRegressor` usando um pipeline robusto e `GridSearchCV` para otimizaÃ§Ã£o, e salva o modelo treinado e suas mÃ©tricas.

```bash
python main.py
```
* **Entrada:** `database/dataset_para_modelo.csv`.
* **SaÃ­da:** Cria a pasta `data/` e, dentro dela, os arquivos:
    * `modelo_vendas.pkl` (o pipeline completo do modelo).
    * `model_metrics.json` (as mÃ©tricas de desempenho, como RÂ² e MSE).
    * `encoders.pkl` (os nomes das features processadas).

![diagnostico_previsoes.png](img/diagnostico_previsoes.png)
![importancia_features.png](img/importancia_features.png)
![segmento_cliente.png](img/segmento_cliente.png)
![valor_venda_distribuicao.png](img/valor_venda_distribuicao.png)

### Passo 4: Executar o Dashboard Interativo
Finalmente, este script inicia a aplicaÃ§Ã£o web com Streamlit, onde vocÃª pode interagir com o modelo, fazer previsÃµes e gerar relatÃ³rios.

```bash
streamlit run dashboard.py
```
* **Entrada:** Os artefatos nas pastas `data_processed/` e `data/`.
* **SaÃ­da:** Uma aplicaÃ§Ã£o web interativa serÃ¡ aberta no seu navegador.


### Passo 5: AnÃ¡lise dos Dados (Opcional)
Este script gerar os graficos de Histograma, assimetria positiva, Log do Valor, Top 15 Categorias de Produtos Mais Vendidas, Valor do Pagamento por Tipo de Pagamento e Matriz de CorrelaÃ§Ã£o entre Features NumÃ©ricas

```bash
python analise_dados.py
```

![Figure_1.png](Figure_1.png)
![Figure_2.png](Figure_2.png)
![Figure_3.png](Figure_3.png)
![Figure_4.png](Figure_4.png)
![Figure_5.png](Figure_5.png)

## ğŸ“œ DescriÃ§Ã£o dos Scripts

* **`preparar_dados.py`**: ResponsÃ¡vel pela junÃ§Ã£o (merge) de todas as fontes de dados em um Ãºnico arquivo CSV.
* **`engenharia_features.py`**: Realiza a limpeza dos dados, tratamento de valores faltantes e criaÃ§Ã£o de novas colunas (features) para melhorar o desempenho do modelo.
* **`main.py`**: ContÃ©m todo o pipeline de Machine Learning, incluindo prÃ©-processamento, treinamento com validaÃ§Ã£o cruzada, otimizaÃ§Ã£o e avaliaÃ§Ã£o do modelo.
* **`dashboard.py`**: Cria a interface de usuÃ¡rio com Streamlit, permitindo a interaÃ§Ã£o com o modelo treinado para fazer previsÃµes e analisar seus resultados.
